{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Assignment 2: Feature Selection**\n",
        "Sonia Wu and Avital Palchik (Group 26)\n",
        "\n",
        "Machine Learning for Business Decision Making, Assignment 2\n",
        "\n",
        "Due December 15th, 23:59"
      ],
      "metadata": {
        "id": "auYeJ5RvO-k6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "## Step 1\n",
        "\n",
        "To build our final model, we will start with the same dataset and pipeline as Assignment 1. To start, we import all the libraries we will need for this assignment, and set up the seed, file paths, and import the data.\n",
        "\n",
        "We also have to preprocess in the same way we did for assignment 1:\n",
        "- For the `pdays` variable, we create a new variable `was_contacted` and replace the -1 values with 0\n",
        "- We use the Holdout method with the established test set of size 20%\n",
        "\n",
        "Our best model from Assignment 1 was Gradient Boosting with RandomSearch HPO. For this assignment, we use the same model architecture with default hyperparameters (to be able to analyze feature selection methods)."
      ],
      "metadata": {
        "id": "2o04o95LOt9N"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z0IbMdp0On7Q",
        "outputId": "215cdae1-3af8-45ee-ad9f-cfd6ee3a650c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data loaded successfully.\n",
            "Data restored and split.\n",
            "Training shape: (8800, 17)\n",
            "Test shape: (2200, 17)\n"
          ]
        }
      ],
      "source": [
        "# 1. imports\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pickle\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.feature_selection import SelectKBest, f_classif, mutual_info_classif\n",
        "from sklearn.ensemble import HistGradientBoostingClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# 2. setup\n",
        "STUDENT_ID = 100574955\n",
        "np.random.seed(STUDENT_ID)\n",
        "\n",
        "# 3. load data\n",
        "try:\n",
        "    df = pd.read_pickle('bank_26.pkl')\n",
        "    df_comp = pd.read_pickle('bank_competition.pkl')\n",
        "    print(\"Data loaded successfully.\")\n",
        "except FileNotFoundError:\n",
        "    print(\"Error: Files not found. Ensure bank_26.pkl is in the folder.\")\n",
        "\n",
        "# 4. feature engineering\n",
        "def clean_data(dataframe):\n",
        "    df_copy = dataframe.copy()\n",
        "    # create the binary flag\n",
        "    df_copy['was_contacted'] = (df_copy['pdays'] != -1).astype(int)\n",
        "    # replace -1 with 0 to fix the scale\n",
        "    df_copy['pdays'] = df_copy['pdays'].replace(-1, 0)\n",
        "    return df_copy\n",
        "\n",
        "df_clean = clean_data(df)\n",
        "\n",
        "# 5. split X and y\n",
        "X = df_clean.drop('deposit', axis=1)\n",
        "y = df_clean['deposit']\n",
        "\n",
        "# 6. train/test split (0.2)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=STUDENT_ID, stratify=y)\n",
        "\n",
        "print(\"Data restored and split.\")\n",
        "print(f\"Training shape: {X_train.shape}\")\n",
        "print(f\"Test shape: {X_test.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## Step 2\n",
        "Next, we want to preprocess our data (filling in missing data, scaling numerical features, and converting text categories into numbers). We will create two different pipelines with the two different feature selection methods: one will use `f_classif`, and the other will use `mutual_info_classif`. This will allow us to compare the two methods."
      ],
      "metadata": {
        "id": "GxiwYHXPXc2D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. redefine the preprocessing\n",
        "categorical_cols = X.select_dtypes(include=['object', 'category']).columns.tolist()\n",
        "numerical_cols = X.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
        "\n",
        "# define steps\n",
        "num_pipeline = Pipeline([\n",
        "    ('imputer', SimpleImputer(strategy='median')),\n",
        "    ('scaler', StandardScaler())\n",
        "])\n",
        "\n",
        "cat_pipeline = Pipeline([\n",
        "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
        "    ('encoder', OneHotEncoder(handle_unknown='ignore', sparse_output=False))\n",
        "])\n",
        "\n",
        "preprocessor = ColumnTransformer([\n",
        "    ('num', num_pipeline, numerical_cols),\n",
        "    ('cat', cat_pipeline, categorical_cols)\n",
        "])\n",
        "\n",
        "# 2. define the model (Gradient Boosting with default parameters)\n",
        "gb_model = HistGradientBoostingClassifier(random_state=STUDENT_ID)\n",
        "\n",
        "# 3. create the two pipelines (f_classif and mutual_info_classif)\n",
        "# pipeline A: f_classif\n",
        "pipe_f = Pipeline([\n",
        "    ('preprocessor', preprocessor),\n",
        "    ('selector', SelectKBest(score_func=f_classif)),\n",
        "    ('classifier', gb_model)\n",
        "])\n",
        "\n",
        "# pipeline B: mutual_info_classif\n",
        "pipe_mutual = Pipeline([\n",
        "    ('preprocessor', preprocessor),\n",
        "    ('selector', SelectKBest(score_func=mutual_info_classif)),\n",
        "    ('classifier', gb_model)\n",
        "])"
      ],
      "metadata": {
        "id": "IdQwRdQhPp6q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## Step 3\n",
        "Now, we will test values of `k` (number of features to be selected) using a grid search. We started with keeping 5 features, and then 10, 15, 20, and so on, up to 'all'. After OneHotEncoding, we should have 53 different features.\n",
        "\n"
      ],
      "metadata": {
        "id": "tyVH4eSrZbVO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. define the Grid for k\n",
        "param_grid = {\n",
        "    'selector__k': [5, 10, 15, 20, 25, 'all']\n",
        "}\n",
        "\n",
        "# 2. run the Grid Search to tune k\n",
        "def run_selection_search(name, pipeline, X_train, y_train):\n",
        "    print(f\"Running Grid Search for {name}...\")\n",
        "\n",
        "    grid = GridSearchCV(\n",
        "        pipeline,\n",
        "        param_grid,\n",
        "        cv=5,                 # we use 5-fold cross-validation\n",
        "        scoring='accuracy',   # metric is still accuracy\n",
        "        n_jobs=-1             # we use all CPU cores\n",
        "    )\n",
        "\n",
        "    grid.fit(X_train, y_train)\n",
        "\n",
        "    print(f\"  Best Accuracy: {grid.best_score_:.4f}\")\n",
        "    print(f\"  Best k (Number of Features): {grid.best_params_['selector__k']}\")\n",
        "    return grid\n",
        "\n",
        "# 3. run and collect results for both pipelines\n",
        "results_f = run_selection_search(\"ANOVA (f_classif)\", pipe_f, X_train, y_train)\n",
        "print(\"-\" * 30)\n",
        "results_mutual = run_selection_search(\"Mutual Info\", pipe_mutual, X_train, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mhzUIdloQ634",
        "outputId": "ece4aa08-93f1-4fd2-8e13-645c9b9f6f23"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running Grid Search for ANOVA (f_classif)...\n",
            "  Best Accuracy: 0.8660\n",
            "  Best k (Number of Features): all\n",
            "------------------------------\n",
            "Running Grid Search for Mutual Info...\n",
            "  Best Accuracy: 0.8660\n",
            "  Best k (Number of Features): all\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## Step 4\n",
        "\n",
        "As we can see, both models perform the same. The best number of features to use is all the features (so all 53). This makes sense because we are using Gradient Boosting, which already eliminates useless features. This implies that explicit feature removal did not improve performance.\n",
        "\n",
        "This also means both models (`f_classif` and `mutual_info_classif`), in this case, have the same accuracy.\n",
        "\n",
        "Moving on to the next step, we want to see which features are actually selected and why they are selected. Note that GridSearchCV was performed on the training set only, and the test set was used once for final evaluation."
      ],
      "metadata": {
        "id": "6MNmUPRXcIRd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. get the feature names\n",
        "# we need to fit the preprocessor to know the names of the OHE columns\n",
        "preprocessor.fit(X_train, y_train)\n",
        "feature_names = preprocessor.get_feature_names_out()\n",
        "\n",
        "# print which feature names have been selected for each method\n",
        "selected_f = feature_names[\n",
        "    results_f.best_estimator_.named_steps['selector'].get_support()\n",
        "]\n",
        "\n",
        "selected_m = feature_names[\n",
        "    results_mutual.best_estimator_.named_steps['selector'].get_support()\n",
        "]\n",
        "\n",
        "print(\"\\nSelected features (ANOVA):\")\n",
        "print(selected_f.tolist())\n",
        "\n",
        "print(\"\\nSelected features (Mutual Info):\")\n",
        "print(selected_m.tolist())\n",
        "\n",
        "\n",
        "print(f\"Total features after One-Hot Encoding: {len(feature_names)}\")\n",
        "\n",
        "# 2. extract scores from the best estimators\n",
        "# we access the 'selector' step inside the best pipeline found by GridSearch\n",
        "anova_scores = results_f.best_estimator_.named_steps['selector'].scores_\n",
        "mutual_scores = results_mutual.best_estimator_.named_steps['selector'].scores_\n",
        "\n",
        "# 3. create a dataframe to compare rankings\n",
        "df_scores = pd.DataFrame({\n",
        "    'Feature': feature_names,\n",
        "    'ANOVA Score': anova_scores,\n",
        "    'Mutual Info Score': mutual_scores\n",
        "})\n",
        "\n",
        "# 4. show top 10 features by ANOVA\n",
        "print(\"\\n--- TOP 10 FEATURES (ANOVA) ---\")\n",
        "print(df_scores.sort_values(by='ANOVA Score', ascending=False).head(10))\n",
        "\n",
        "# 5. show top 10 features by Mutual Info\n",
        "print(\"\\n--- TOP 10 FEATURES (MUTUAL INFO) ---\")\n",
        "print(df_scores.sort_values(by='Mutual Info Score', ascending=False).head(10))\n",
        "\n",
        "# 6. final evaluation on test dataset\n",
        "print(\"\\n--- FINAL TEST EVALUATION ---\")\n",
        "\n",
        "# evaluate ANOVA pipeline\n",
        "y_pred_f = results_f.predict(X_test)\n",
        "acc_f = accuracy_score(y_test, y_pred_f)\n",
        "print(f\"Test Accuracy (ANOVA - k={results_f.best_params_['selector__k']}): {acc_f:.4f}\")\n",
        "\n",
        "# evaluate Mutual Info pipeline\n",
        "y_pred_m = results_mutual.predict(X_test)\n",
        "acc_m = accuracy_score(y_test, y_pred_m)\n",
        "print(f\"Test Accuracy (Mutual Info - k={results_mutual.best_params_['selector__k']}): {acc_m:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8YYbrwjuRraj",
        "outputId": "589f7575-c82d-4512-8a21-2d0e3384e9b1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Selected features (ANOVA):\n",
            "['num__age', 'num__balance', 'num__day', 'num__duration', 'num__campaign', 'num__pdays', 'num__previous', 'num__was_contacted', 'cat__job_admin.', 'cat__job_blue-collar', 'cat__job_entrepreneur', 'cat__job_housemaid', 'cat__job_management', 'cat__job_retired', 'cat__job_self-employed', 'cat__job_services', 'cat__job_student', 'cat__job_technician', 'cat__job_unemployed', 'cat__job_unknown', 'cat__marital_divorced', 'cat__marital_married', 'cat__marital_single', 'cat__marital_None', 'cat__education_primary', 'cat__education_secondary', 'cat__education_tertiary', 'cat__education_unknown', 'cat__default_no', 'cat__default_yes', 'cat__housing_no', 'cat__housing_yes', 'cat__loan_no', 'cat__loan_yes', 'cat__contact_cellular', 'cat__contact_telephone', 'cat__contact_unknown', 'cat__month_apr', 'cat__month_aug', 'cat__month_dec', 'cat__month_feb', 'cat__month_jan', 'cat__month_jul', 'cat__month_jun', 'cat__month_mar', 'cat__month_may', 'cat__month_nov', 'cat__month_oct', 'cat__month_sep', 'cat__poutcome_failure', 'cat__poutcome_other', 'cat__poutcome_success', 'cat__poutcome_unknown']\n",
            "\n",
            "Selected features (Mutual Info):\n",
            "['num__age', 'num__balance', 'num__day', 'num__duration', 'num__campaign', 'num__pdays', 'num__previous', 'num__was_contacted', 'cat__job_admin.', 'cat__job_blue-collar', 'cat__job_entrepreneur', 'cat__job_housemaid', 'cat__job_management', 'cat__job_retired', 'cat__job_self-employed', 'cat__job_services', 'cat__job_student', 'cat__job_technician', 'cat__job_unemployed', 'cat__job_unknown', 'cat__marital_divorced', 'cat__marital_married', 'cat__marital_single', 'cat__marital_None', 'cat__education_primary', 'cat__education_secondary', 'cat__education_tertiary', 'cat__education_unknown', 'cat__default_no', 'cat__default_yes', 'cat__housing_no', 'cat__housing_yes', 'cat__loan_no', 'cat__loan_yes', 'cat__contact_cellular', 'cat__contact_telephone', 'cat__contact_unknown', 'cat__month_apr', 'cat__month_aug', 'cat__month_dec', 'cat__month_feb', 'cat__month_jan', 'cat__month_jul', 'cat__month_jun', 'cat__month_mar', 'cat__month_may', 'cat__month_nov', 'cat__month_oct', 'cat__month_sep', 'cat__poutcome_failure', 'cat__poutcome_other', 'cat__poutcome_success', 'cat__poutcome_unknown']\n",
            "Total features after One-Hot Encoding: 53\n",
            "\n",
            "--- TOP 10 FEATURES (ANOVA) ---\n",
            "                  Feature  ANOVA Score  Mutual Info Score\n",
            "3           num__duration  2202.827963           0.156057\n",
            "51  cat__poutcome_success   811.570340           0.046809\n",
            "36   cat__contact_unknown   645.185550           0.028089\n",
            "7      num__was_contacted   515.576630           0.033090\n",
            "52  cat__poutcome_unknown   513.354848           0.034182\n",
            "34  cat__contact_cellular   471.516814           0.038168\n",
            "23      cat__marital_None   386.245357           0.024146\n",
            "30        cat__housing_no   372.134130           0.013780\n",
            "31       cat__housing_yes   372.134130           0.030649\n",
            "45         cat__month_may   273.932817           0.013701\n",
            "\n",
            "--- TOP 10 FEATURES (MUTUAL INFO) ---\n",
            "                  Feature  ANOVA Score  Mutual Info Score\n",
            "3           num__duration  2202.827963           0.156057\n",
            "5              num__pdays   210.843940           0.050571\n",
            "1            num__balance    69.700006           0.047845\n",
            "51  cat__poutcome_success   811.570340           0.046809\n",
            "34  cat__contact_cellular   471.516814           0.038168\n",
            "52  cat__poutcome_unknown   513.354848           0.034182\n",
            "7      num__was_contacted   515.576630           0.033090\n",
            "31       cat__housing_yes   372.134130           0.030649\n",
            "0                num__age    11.202524           0.029292\n",
            "36   cat__contact_unknown   645.185550           0.028089\n",
            "\n",
            "--- FINAL TEST EVALUATION ---\n",
            "Test Accuracy (ANOVA - k=all): 0.8718\n",
            "Test Accuracy (Mutual Info - k=all): 0.8718\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## Analysis\n",
        "Even though the grid search revealed that it would be best to use all features for both pipelines, we can still learn from which features held the most weight:\n",
        "- Top Shared Features: Both methods agreed that `duration` (last contact duration) and `poutcome_success` (previous campaign outcome) were the most critical predictors.\n",
        "- ANOVA (Linear): Prioritized categorical flags like `contact_unknown` and `marital_None`. It favoured simple \"Yes/No\" splits.\n",
        "- Mutual Information (Non-Linear): Prioritized numerical variables like `pdays`, `balance`, and `age`. It would also be able to capture complex, non-linear relationships that ANOVA misses (e.g., the U-shaped relationship where both very young and very old people are more likely to subscribe).\n",
        "\n",
        "Both SelectKBest methods selected all available features (`k = 53`), indicating that removing features reduced cross-validated accuracy. This is expected when using tree-based models such as Gradient Boosting, which perform implicit feature selection during training. As a result, neither ANOVA nor Mutual Information improved performance compared to Assignment 1.\n",
        "\n",
        "Our original model remained comparable between the two assignments. Any slight accuracy differences are likely due to switching our parameters to the default settings, rather than the feature selection. To finish off the assignment, we will retrain the model and make our predictions."
      ],
      "metadata": {
        "id": "K6kqyPdFe-li"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. retrain the winner on FULL data\n",
        "# since both pipelines chose 'all' features and had the same accuracy,\n",
        "# we can use the Mutual Info pipeline\n",
        "# we fit it on X (all training data) and y.\n",
        "print(\"Retraining final model on full dataset...\")\n",
        "\n",
        "final_pipeline = results_mutual.best_estimator_\n",
        "final_pipeline.fit(X, y)\n",
        "\n",
        "print(\"Final model retrained successfully.\")\n",
        "\n",
        "# 2. process competition data\n",
        "# we must apply the 'pdays' fix to the competition data again\n",
        "print(\"Processing competition data...\")\n",
        "\n",
        "# apply the manual function we wrote in assignment 1\n",
        "df_comp_clean = clean_data(df_comp)\n",
        "\n",
        "# ensure columns match X, make sure we feed the pipeline the same columns as X\n",
        "X_comp = df_comp_clean[X.columns]\n",
        "\n",
        "# 3. make predictions\n",
        "comp_predictions = final_pipeline.predict(X_comp)\n",
        "print(f\"Predictions generated. First 5: {comp_predictions[:5]}\")\n",
        "\n",
        "# 4. save files\n",
        "# A. the predictions CSV\n",
        "submission_filename = 'group_26_assignment2_prediction.csv'\n",
        "pd.DataFrame(comp_predictions, columns=['prediction']).to_csv(submission_filename, index=False)\n",
        "print(f\"Saved predictions to {submission_filename}\")\n",
        "\n",
        "# B. the model pkl file\n",
        "model_filename = 'group_26_assignment2_model.pkl'\n",
        "with open(model_filename, 'wb') as file:\n",
        "    pickle.dump(final_pipeline, file)\n",
        "print(f\"Saved model to {model_filename}\")\n",
        "\n",
        "print(\"\\n--- ASSIGNMENT 2 COMPLETE ---\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zKCeZPjnTctH",
        "outputId": "60db8144-7963-478c-c8c6-33f52da17260"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Retraining final model on full dataset...\n",
            "Final model retrained successfully.\n",
            "Processing competition data...\n",
            "Predictions generated. First 5: ['no' 'yes' 'no' 'yes' 'yes']\n",
            "Saved predictions to group_26_assignment2_prediction.csv\n",
            "Saved model to group_26_assignment2_model.pkl\n",
            "\n",
            "--- ASSIGNMENT 2 COMPLETE ---\n"
          ]
        }
      ]
    }
  ]
}